# name: test/sql/local/irc_any_catalog/update/update_join_duplicates.test
# description: Test ducklake update using a join with duplicates
# group: [update]

require-env ICEBERG_SERVER_AVAILABLE

require-env SECRETS_CREATED_AND_CATALOG_ATTACHED

require avro

require parquet

require iceberg

require httpfs

require core_functions

# Do not ignore 'HTTP' error messages!
set ignore_error_messages

statement ok
CALL enable_logging('HTTP');

statement ok
set logging_level='debug'

statement ok
DROP TABLE IF EXISTS my_datalake.default.test;

statement ok
CREATE TABLE my_datalake.default.test AS SELECT i id FROM range(5) t(i);

statement ok
CREATE TEMPORARY TABLE updated_rows AS FROM range(0, 10, 2) t(update_id) UNION ALL FROM range(0, 10, 2);

# duplicate row-id updates are not yet supported
statement ok
BEGIN

statement ok
INSERT INTO my_datalake.default.test FROM range(5, 10)

statement error
UPDATE my_datalake.default.test SET id=id+1000 FROM updated_rows WHERE id=updated_rows.update_id
----
The same row was updated multiple times

statement ok
ROLLBACK

# we can update through a join if we filter out the duplciate row ids
statement ok
BEGIN

statement ok
INSERT INTO my_datalake.default.test FROM range(5, 10)

statement ok
UPDATE my_datalake.default.test SET id=id+1000 FROM (SELECT DISTINCT update_id FROM updated_rows) updated_rows WHERE id=updated_rows.update_id

query III
SELECT COUNT(*), SUM(id), AVG(id) FROM my_datalake.default.test
----
10	5045	504.5

statement ok
COMMIT

query III
SELECT COUNT(*), SUM(id), AVG(id) FROM my_datalake.default.test
----
10	5045	504.5


