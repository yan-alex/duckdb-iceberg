# name: test/sql/local/iceberg_scans/iceberg_scan_schema_evo_timetravel.test
# group: [iceberg_scans]

require avro

require parquet

require iceberg

require httpfs

require-env ICEBERG_SERVER_AVAILABLE

statement ok
CREATE SECRET (
    TYPE S3,
    KEY_ID 'admin',
    SECRET 'password',
    ENDPOINT '127.0.0.1:9000',
    URL_STYLE 'path',
    USE_SSL 0
);


statement ok
ATTACH 'demo' AS my_datalake (
	TYPE ICEBERG,
	CLIENT_ID 'admin',
	CLIENT_SECRET 'password',
	ENDPOINT 'http://127.0.0.1:8181'
);

query I
select count(snapshot_id::BIGINT) from iceberg_snapshots(
	my_datalake.default.pyspark_iceberg_table_v2
)
----
8

statement ok
set variable last_snapshot = (
	select snapshot_id::BIGINT from iceberg_snapshots(
		my_datalake.default.pyspark_iceberg_table_v2
	) order by timestamp_ms
	offset 7 limit 1
)

# Spark seemingly messed something up here,
# because they removed DEFAULT support.
# So in our tests DEFAULT has been replaced by ALTER + UPDATE and somehow the count is all messed up because of this.
mode skip

query I
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (VERSION => getvariable('last_snapshot')) WHERE schema_evol_added_col_1 IS NOT NULL;
----
685

query I
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (TIMESTAMP => now()::TIMESTAMP) WHERE schema_evol_added_col_1 IS NOT NULL;
----
685

query I
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (TIMESTAMP => now()) WHERE schema_evol_added_col_1 IS NOT NULL;
----
685

statement error
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (TIMESTAMP => 'hi there') WHERE schema_evol_added_col_1 IS NOT NULL;
----
Invalid Input Error: Failed to cast value

statement error
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (VERSION => 'hi there') WHERE schema_evol_added_col_1 IS NOT NULL;
----
Invalid Input Error: Failed to cast value

statement error
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (VERSION => 1) WHERE schema_evol_added_col_1 IS NOT NULL;
----
Invalid Configuration Error: Could not find snapshot with id 1

statement error
select
	count(schema_evol_added_col_1)
from
	my_datalake.default.pyspark_iceberg_table_v2 AT (VERSION => 1.0) WHERE schema_evol_added_col_1 IS NOT NULL;
----
Invalid Configuration Error: Could not find snapshot with id 1

