name: Test Spark Catalog Reusable
on:
  workflow_call:
    inputs:
      artifact-name:
        description: "Name of the DuckDB-Iceberg artifact to download"
        required: true
        type: string

jobs:
  test-spark:
    name: Test against Spark Catalog
    runs-on: ubuntu-latest
    env:
      HTTP_PROXY_PUBLIC: localhost:8878

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: 'true'

      - name: Download DuckDB-Iceberg artifact
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.artifact-name }}
          path: build/release

      - name: Restore permissions
        run: |
          find ./build/release -type f -name 'duckdb*' -exec chmod +x {} \;
          find ./build/release -type f -name 'unittest*' -exec chmod +x {} \;

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '21'

      - name: Set up Docker Compose
        uses: docker/setup-compose-action@v1

      - name: Install Spark Catalog dependencies
        run: |
          sudo apt update -y -qq
          sudo apt install -y -qq python3-venv tar pkg-config

      - name: Install CMake 3.x
        run: |
          sudo apt-get remove -y cmake cmake-data
          sudo apt-get install --allow-downgrades -y -qq 'cmake=3.*' 'cmake-data=3.*'

      - uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Install required python packages
        run: |
          python3 -m venv .venv-spark4
          source .venv-spark4/bin/activate
          python3 -m pip install -r scripts/requirements.txt

      - name: Generate data
        run: |
          source .venv-spark4/bin/activate
          make data

      - name: Run mitmproxy
        shell: bash
        run: |
          python3 mitmdump --mode regular@8878 --flow-detail 2 > mitmproxy.log 2>&1 &

      - name: Test with rest catalog
        env:
          ICEBERG_SERVER_AVAILABLE: 1
          DUCKDB_ICEBERG_HAVE_GENERATED_DATA: 1
        run: |
          source .venv-spark4/bin/activate
          make test_release

      - name: Test reads with PyIceberg
        env:
          ICEBERG_SERVER_AVAILABLE: 1
        run: |
          python3 -m venv .venv-spark3
          source .venv-spark3/bin/activate
          python3 -m pip install pyspark==3.5.2 pytest pyiceberg==0.9.1 pyarrow pydantic==2.9.0
          python3 -m pytest test/python
